## ğŸ“Š Customer Churn Prediction
This project predicts customer churn using machine learning techniques. It is based on a telecom dataset and includes a variety of models (Logistic Regression, Random Forest, Decision Tree) with class imbalance handling strategies such as SMOTE oversampling and class weighting.

## ğŸš€ Project Overview
Goal: Predict whether a customer will churn (leave the company) or not.

Data: Telecom customer data with demographic, service, and billing information.

Approach: Train multiple models, compare performance, and interpret feature importance for stakeholder insights.

## âš™ï¸ Features Used
Examples of features:

Gender

Senior Citizen status

Partner

Dependents

Tenure

Phone Service

Multiple Lines

Internet Service

Online Security

Contract Type

Monthly Charges

â€¦ and other relevant attributes

## ğŸ§® Models Applied
âœ… Logistic Regression

Baseline model

Tested with and without class balancing (class_weight='balanced')

SMOTE applied to oversample minority class

âœ… Random Forest

Tested with standard settings and then with class_weight='balanced'

Tuned with parameters:

n_estimators=500

max_leaf_nodes=30

max_features='sqrt'

Evaluated using ROC curve and AUC

âœ… Decision Tree

Tested with and without class balancing

Compared on precision, recall, and f1-score

## ğŸ“ˆ Model Performance
Random Forest (balanced) achieved:

~80% overall accuracy

Class 1 (churn) recall improved to ~0.77

AUC around 0.83

Logistic Regression with SMOTE:

Slightly lower accuracy but better churn recall

Decision Tree:

Simpler but less robust compared to Random Forest

## ğŸ” Interpretation
Key insights:

Tenure is highly important (short tenure â†’ higher churn)

Monthly Charges influences churn (higher bills â†’ higher churn)

Contract Type (month-to-month contracts â†’ higher churn)

Feature importance from the Random Forest helps stakeholders prioritize retention strategies.

## ğŸ–¥ï¸ How to Run
Clone the repository
Run the notebook:
jupyter notebook ChurnPrediction.ipynb
Explore the results in the notebook (ROC curves, classification reports, feature importance plots).


## ğŸ™Œ Acknowledgements
Scikit-learn
imbalanced-learn
Matplotlib, Seaborn, Plotly
